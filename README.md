# Sarcasm Detection using Hierarchical BERT

This project implements a Hierarchical BERT-based architecture for sarcasm detection, inspired by the ACL 2020 paper â€œA Novel Hierarchical BERT Architecture for Sarcasm Detectionâ€. The model leverages contextual information from conversation history to classify a response as sarcastic or non-sarcastic.

#ğŸ“Œ Project Overview

Sarcasm often depends on context rather than isolated sentences. This project addresses that challenge by modeling text in a hierarchical manner:

Word-level encoding using BERT

Sentence-level summarization using CNN

Context-level temporal modeling using BiLSTM

Contextâ€“response interaction using convolutional layers

#ğŸ§  Model Architecture

BERT for contextual word embeddings

CNN for sentence and context summarization

BiLSTM to capture temporal dependencies in dialogue

Fully Connected + Sigmoid for final classification

The architecture enables effective utilization of conversation history for sarcasm detection.


#ğŸ“Š Dataset

The original research evaluates the model on Twitter and Reddit datasets from the FigLang 2020 Shared Task.
This repository focuses on model implementation and experimentation. Dataset files are not included due to licensing constraints.


#ğŸ›  Requirements

Python 3.8+

TensorFlow / PyTorch

HuggingFace Transformers

NumPy, Pandas, Scikit-learn

Jupyter Notebook

#ğŸ“ˆ Output

Binary classification: Sarcastic / Non-Sarcastic

Confidence scores using sigmoid probability

Model evaluation using accuracy and F1-score

#âš ï¸ Disclaimer

This is an independent implementation created for educational and research purposes.
It is inspired by, but not an official reproduction of, the original research paper.

#ğŸ“š Reference

Himani Srivastava et al., A Novel Hierarchical BERT Architecture for Sarcasm Detection, ACL 2020.

#ğŸ‘¤ Author

Nitesh Duhan
Data Science & NLP Enthusiast
